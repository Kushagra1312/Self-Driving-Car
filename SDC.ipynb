{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SDCCOPY.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "n2JZ2tY-Q8Vk"
      },
      "source": [
        "import zipfile\n",
        "zip_ref = zipfile.ZipFile(\"/content/drive/My Drive/Colab Notebooks/SDC/driving_dataset.zip\", 'r')\n",
        "zip_ref.extractall(\"/content/data\")\n",
        "zip_ref.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hg6gWWXhRE9V"
      },
      "source": [
        "import pandas\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing import image\n",
        "import keras\n",
        "\n",
        "data = pandas.read_csv('/content/drive/My Drive/Colab Notebooks/SDC/data.txt',header = None,sep=' ' )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7rMZKJxFRG9a"
      },
      "source": [
        "data=data.values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-KVIE2oRJZL"
      },
      "source": [
        "x_data = data[:,0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdlUH70_RLv1"
      },
      "source": [
        "y_data=data[:,-1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9jWnKneVRN3K"
      },
      "source": [
        "length=int((x_data.shape[0])*0.8)\n",
        "xtrain = x_data[:length]\n",
        "ytrain = y_data[:length]\n",
        "xtest = x_data[length:]\n",
        "ytest = y_data[length:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1WtDxYDyR_Io"
      },
      "source": [
        "import random\n",
        "c = list(zip(xtrain,ytrain))\n",
        "random.shuffle(c)\n",
        "xtrain,ytrain = zip(*c)\n",
        "\n",
        "\n",
        "c = list(zip(xtest,ytest))\n",
        "random.shuffle(c)\n",
        "xtest,ytest = zip(*c)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qWqCuZHFaXW4",
        "outputId": "17131c46-7e0e-43b7-a602-42aca25b3c59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        }
      },
      "source": [
        "xtrain[200]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'35763.jpg'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iuo5GbMqSBZG"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Cropping2D,Conv2D,Flatten, Dense, Dropout, BatchNormalization, LeakyReLU, MaxPool2D\n",
        "from keras.optimizers import Adam\n",
        "from keras import regularizers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IAfL9_jTSDKx"
      },
      "source": [
        "import tensorflow as tf\n",
        "from keras.layers import Lambda"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5r3hKRnxSFm1",
        "outputId": "0fe02e41-b4c9-4209-efa6-f5b0b679a99c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\n",
        "model = Sequential()\n",
        "\n",
        "\n",
        "model.add(Cropping2D(((80,0), (0, 0)), input_shape=(160, 320, 3)))\n",
        "model.add(Lambda(lambda x: tf.image.resize(x, (66, 200))))\n",
        "\n",
        "model.add(Conv2D(24, (5, 5), activation='relu', input_shape=(200, 200, 3), strides=(2, 2), kernel_regularizer=regularizers.l2(0.001)))\n",
        "\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv2D(36, (5, 5), activation='relu', strides=(2, 2), kernel_regularizer=regularizers.l2(0.001)))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv2D(48, (5, 5), activation='relu', strides=(2, 2), kernel_regularizer=regularizers.l2(0.001)))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), activation='relu',kernel_regularizer=regularizers.l2(0.001)))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), activation='relu',kernel_regularizer=regularizers.l2(0.001)))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(1164, activation='relu',kernel_regularizer=regularizers.l2(0.001)))\n",
        "\n",
        "model.add(Dense(200, activation='relu',kernel_regularizer=regularizers.l2(0.001)))\n",
        "\n",
        "model.add(Dense(128, activation='relu',kernel_regularizer=regularizers.l2(0.001)))\n",
        "\n",
        "model.add(Dense(50, activation='relu',kernel_regularizer=regularizers.l2(0.001)))\n",
        "\n",
        "model.add(Dense(1, activation='tanh', kernel_regularizer=regularizers.l2(0.001)))\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "cropping2d_1 (Cropping2D)    (None, 80, 320, 3)        0         \n",
            "_________________________________________________________________\n",
            "lambda_1 (Lambda)            (None, 66, 200, 3)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 31, 98, 24)        1824      \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 31, 98, 24)        96        \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 14, 47, 36)        21636     \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 14, 47, 36)        144       \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 5, 22, 48)         43248     \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 5, 22, 48)         192       \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 3, 20, 64)         27712     \n",
            "_________________________________________________________________\n",
            "batch_normalization_8 (Batch (None, 3, 20, 64)         256       \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 1, 18, 128)        73856     \n",
            "_________________________________________________________________\n",
            "batch_normalization_9 (Batch (None, 1, 18, 128)        512       \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 2304)              0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 1164)              2683020   \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 200)               233000    \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 128)               25728     \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 50)                6450      \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 1)                 51        \n",
            "=================================================================\n",
            "Total params: 3,117,725\n",
            "Trainable params: 3,117,125\n",
            "Non-trainable params: 600\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6rg52PfPSJXW"
      },
      "source": [
        "model.compile(optimizer = Adam(0.001),loss = 'mse',metrics=['mae'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g0IQCZTVYtep"
      },
      "source": [
        "import cv2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4UoPjCQCSK5z"
      },
      "source": [
        "from keras.preprocessing import image\n",
        "\n",
        "def LoadBatch(batch_size,i,xdata,ydata):\n",
        "  xd=[]\n",
        "  yd=[]\n",
        "  pointer=0\n",
        "  if i==len(xdata)//batch_size-1:\n",
        "    batch_size=len(xdata)%batch_size\n",
        "  while pointer<batch_size:\n",
        "    img=image.load_img(\"/content/data/driving_dataset/\"+xdata[(pointer+i*batch_size)%l],color_mode='rgb',target_size=[160,320])\n",
        "    img = image.img_to_array(img)/255.0\n",
        "    xd.append(img)\n",
        "    yd.append(ydata[(pointer+i*batch_size)%l]*np.pi/180)\n",
        "    pointer = pointer+1\n",
        "  return np.array(xd),np.array(yd)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HTcEFYE4SNC-",
        "outputId": "40109499-05c1-43c6-b0f1-984a20a4dc53",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "c=0\n",
        "l=len(xtest)\n",
        "epochs=5\n",
        "batch_size=128\n",
        "num=len(xtrain)\n",
        "for epoch in range(epochs):\n",
        "    for i in range(int(num//batch_size)):\n",
        "        xs, ys = LoadBatch(batch_size,i,xtrain,ytrain)\n",
        "        ys.reshape(-1,1)\n",
        "        model.fit(xs,ys,verbose=0)\n",
        "\n",
        "        if i%10 == 0:\n",
        "            score_train = model.evaluate(xs,ys,verbose=0)\n",
        "            xs1, ys1 = LoadBatch(batch_size,c,xtest,ytest)\n",
        "            c+=1\n",
        "            ys1.reshape(-1,1)\n",
        "            score_test = model.evaluate(xs1,ys1,verbose=0)\n",
        "            print(\"Epoch:%d Step:%d Train loss:%f Train mae:%f Test loss:%f Test mae:%f\\n\"%(epoch+1,i,score_train[0],score_train[1],score_test[0],score_test[1]))\n",
        "        if i%100==0:\n",
        "           model.save_weights(\"/content/drive/My Drive/weightsfinal.h5\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch:1 Step:0 Train loss:2.538924 Train mae:0.262939 Test loss:2.434596 Test mae:0.198002\n",
            "\n",
            "Epoch:1 Step:10 Train loss:2.484872 Train mae:0.290511 Test loss:2.527164 Test mae:0.267014\n",
            "\n",
            "Epoch:1 Step:20 Train loss:2.264842 Train mae:0.302864 Test loss:2.290179 Test mae:0.298919\n",
            "\n",
            "Epoch:1 Step:30 Train loss:2.073703 Train mae:0.363122 Test loss:1.894771 Test mae:0.298780\n",
            "\n",
            "Epoch:1 Step:40 Train loss:1.719134 Train mae:0.307938 Test loss:1.852037 Test mae:0.384802\n",
            "\n",
            "Epoch:1 Step:50 Train loss:1.462034 Train mae:0.247580 Test loss:1.447530 Test mae:0.194520\n",
            "\n",
            "Epoch:1 Step:60 Train loss:1.382548 Train mae:0.322793 Test loss:1.374821 Test mae:0.331787\n",
            "\n",
            "Epoch:1 Step:70 Train loss:1.158234 Train mae:0.260902 Test loss:1.580303 Test mae:0.582201\n",
            "\n",
            "Epoch:1 Step:80 Train loss:0.988323 Train mae:0.258602 Test loss:1.059455 Test mae:0.276478\n",
            "\n",
            "Epoch:1 Step:90 Train loss:0.820432 Train mae:0.206066 Test loss:0.994776 Test mae:0.359906\n",
            "\n",
            "Epoch:1 Step:100 Train loss:1.017567 Train mae:0.316066 Test loss:0.908490 Test mae:0.301301\n",
            "\n",
            "Epoch:1 Step:110 Train loss:0.680883 Train mae:0.234574 Test loss:0.761568 Test mae:0.277505\n",
            "\n",
            "Epoch:1 Step:120 Train loss:0.614395 Train mae:0.217871 Test loss:0.952211 Test mae:0.374294\n",
            "\n",
            "Epoch:1 Step:130 Train loss:0.814416 Train mae:0.392543 Test loss:0.702389 Test mae:0.403416\n",
            "\n",
            "Epoch:1 Step:140 Train loss:0.673772 Train mae:0.257743 Test loss:0.554685 Test mae:0.216711\n",
            "\n",
            "Epoch:1 Step:150 Train loss:0.514097 Train mae:0.237199 Test loss:0.582971 Test mae:0.240077\n",
            "\n",
            "Epoch:1 Step:160 Train loss:0.578500 Train mae:0.241802 Test loss:0.681800 Test mae:0.395817\n",
            "\n",
            "Epoch:1 Step:170 Train loss:0.515604 Train mae:0.241842 Test loss:0.818512 Test mae:0.575351\n",
            "\n",
            "Epoch:1 Step:180 Train loss:0.493171 Train mae:0.262682 Test loss:0.629065 Test mae:0.396254\n",
            "\n",
            "Epoch:1 Step:190 Train loss:0.508048 Train mae:0.269362 Test loss:0.535573 Test mae:0.292793\n",
            "\n",
            "Epoch:1 Step:200 Train loss:0.528749 Train mae:0.249274 Test loss:0.625032 Test mae:0.457192\n",
            "\n",
            "Epoch:1 Step:210 Train loss:0.356798 Train mae:0.181970 Test loss:0.541302 Test mae:0.248598\n",
            "\n",
            "Epoch:1 Step:220 Train loss:0.338918 Train mae:0.173414 Test loss:0.760258 Test mae:0.493163\n",
            "\n",
            "Epoch:1 Step:230 Train loss:0.542176 Train mae:0.287077 Test loss:0.474157 Test mae:0.334836\n",
            "\n",
            "Epoch:1 Step:240 Train loss:0.413128 Train mae:0.239060 Test loss:0.397513 Test mae:0.300978\n",
            "\n",
            "Epoch:1 Step:250 Train loss:0.486453 Train mae:0.296059 Test loss:0.712719 Test mae:0.485737\n",
            "\n",
            "Epoch:1 Step:260 Train loss:0.397867 Train mae:0.220910 Test loss:0.497414 Test mae:0.293983\n",
            "\n",
            "Epoch:1 Step:270 Train loss:0.380010 Train mae:0.214871 Test loss:0.674996 Test mae:0.513445\n",
            "\n",
            "Epoch:1 Step:280 Train loss:0.663477 Train mae:0.300743 Test loss:0.493528 Test mae:0.380598\n",
            "\n",
            "Epoch:2 Step:0 Train loss:0.339077 Train mae:0.257674 Test loss:0.324974 Test mae:0.244031\n",
            "\n",
            "Epoch:2 Step:10 Train loss:0.406858 Train mae:0.243920 Test loss:0.365558 Test mae:0.256516\n",
            "\n",
            "Epoch:2 Step:20 Train loss:0.447751 Train mae:0.226423 Test loss:0.375897 Test mae:0.252526\n",
            "\n",
            "Epoch:2 Step:30 Train loss:0.481914 Train mae:0.298850 Test loss:0.467415 Test mae:0.361431\n",
            "\n",
            "Epoch:2 Step:40 Train loss:0.274117 Train mae:0.181050 Test loss:0.368196 Test mae:0.280393\n",
            "\n",
            "Epoch:2 Step:50 Train loss:0.240740 Train mae:0.149294 Test loss:0.362530 Test mae:0.265362\n",
            "\n",
            "Epoch:2 Step:60 Train loss:0.354627 Train mae:0.219231 Test loss:0.509894 Test mae:0.389174\n",
            "\n",
            "Epoch:2 Step:70 Train loss:0.329395 Train mae:0.189121 Test loss:0.443776 Test mae:0.336744\n",
            "\n",
            "Epoch:2 Step:80 Train loss:0.390077 Train mae:0.263368 Test loss:0.369286 Test mae:0.308876\n",
            "\n",
            "Epoch:2 Step:90 Train loss:0.314291 Train mae:0.236291 Test loss:0.351256 Test mae:0.257349\n",
            "\n",
            "Epoch:2 Step:100 Train loss:0.625239 Train mae:0.350727 Test loss:0.489279 Test mae:0.308150\n",
            "\n",
            "Epoch:2 Step:110 Train loss:0.291482 Train mae:0.232592 Test loss:0.522506 Test mae:0.343229\n",
            "\n",
            "Epoch:2 Step:120 Train loss:0.238189 Train mae:0.178016 Test loss:0.556395 Test mae:0.347426\n",
            "\n",
            "Epoch:2 Step:130 Train loss:0.472897 Train mae:0.347445 Test loss:0.753837 Test mae:0.639176\n",
            "\n",
            "Epoch:2 Step:140 Train loss:0.350618 Train mae:0.216703 Test loss:0.523699 Test mae:0.402888\n",
            "\n",
            "Epoch:2 Step:150 Train loss:0.196690 Train mae:0.151712 Test loss:0.370386 Test mae:0.246810\n",
            "\n",
            "Epoch:2 Step:160 Train loss:0.265273 Train mae:0.185184 Test loss:0.509641 Test mae:0.421237\n",
            "\n",
            "Epoch:2 Step:170 Train loss:0.231488 Train mae:0.148179 Test loss:0.359534 Test mae:0.244411\n",
            "\n",
            "Epoch:2 Step:180 Train loss:0.163366 Train mae:0.118038 Test loss:0.255708 Test mae:0.262947\n",
            "\n",
            "Epoch:2 Step:190 Train loss:0.200974 Train mae:0.156528 Test loss:0.324233 Test mae:0.211016\n",
            "\n",
            "Epoch:2 Step:200 Train loss:0.308282 Train mae:0.199530 Test loss:0.383726 Test mae:0.304437\n",
            "\n",
            "Epoch:2 Step:210 Train loss:0.178044 Train mae:0.183220 Test loss:0.446629 Test mae:0.391912\n",
            "\n",
            "Epoch:2 Step:220 Train loss:0.171077 Train mae:0.137731 Test loss:0.302312 Test mae:0.234266\n",
            "\n",
            "Epoch:2 Step:230 Train loss:0.219700 Train mae:0.153389 Test loss:0.250844 Test mae:0.230585\n",
            "\n",
            "Epoch:2 Step:240 Train loss:0.167636 Train mae:0.155841 Test loss:0.421059 Test mae:0.293052\n",
            "\n",
            "Epoch:2 Step:250 Train loss:0.258778 Train mae:0.172524 Test loss:0.257542 Test mae:0.207816\n",
            "\n",
            "Epoch:2 Step:260 Train loss:0.221220 Train mae:0.149672 Test loss:0.195671 Test mae:0.208468\n",
            "\n",
            "Epoch:2 Step:270 Train loss:0.239822 Train mae:0.197004 Test loss:0.457497 Test mae:0.342847\n",
            "\n",
            "Epoch:2 Step:280 Train loss:0.465690 Train mae:0.205436 Test loss:0.275428 Test mae:0.275791\n",
            "\n",
            "Epoch:3 Step:0 Train loss:0.130167 Train mae:0.135814 Test loss:0.379741 Test mae:0.265425\n",
            "\n",
            "Epoch:3 Step:10 Train loss:0.211814 Train mae:0.202599 Test loss:0.272337 Test mae:0.237739\n",
            "\n",
            "Epoch:3 Step:20 Train loss:0.213886 Train mae:0.167865 Test loss:0.283989 Test mae:0.236393\n",
            "\n",
            "Epoch:3 Step:30 Train loss:0.642498 Train mae:0.437830 Test loss:0.656757 Test mae:0.623059\n",
            "\n",
            "Epoch:3 Step:40 Train loss:0.379313 Train mae:0.314431 Test loss:0.451589 Test mae:0.426709\n",
            "\n",
            "Epoch:3 Step:50 Train loss:0.574677 Train mae:0.544193 Test loss:0.841136 Test mae:0.757644\n",
            "\n",
            "Epoch:3 Step:60 Train loss:0.270292 Train mae:0.196139 Test loss:0.438675 Test mae:0.393971\n",
            "\n",
            "Epoch:3 Step:70 Train loss:0.713721 Train mae:0.430798 Test loss:0.959798 Test mae:0.806674\n",
            "\n",
            "Epoch:3 Step:80 Train loss:0.196806 Train mae:0.168629 Test loss:0.198054 Test mae:0.203891\n",
            "\n",
            "Epoch:3 Step:90 Train loss:0.648733 Train mae:0.545753 Test loss:0.769494 Test mae:0.586976\n",
            "\n",
            "Epoch:3 Step:100 Train loss:0.367332 Train mae:0.234774 Test loss:0.223184 Test mae:0.203539\n",
            "\n",
            "Epoch:3 Step:110 Train loss:0.175231 Train mae:0.159418 Test loss:0.241504 Test mae:0.223434\n",
            "\n",
            "Epoch:3 Step:120 Train loss:0.148043 Train mae:0.123511 Test loss:0.201315 Test mae:0.209116\n",
            "\n",
            "Epoch:3 Step:130 Train loss:0.218205 Train mae:0.165311 Test loss:0.222686 Test mae:0.226382\n",
            "\n",
            "Epoch:3 Step:140 Train loss:0.196847 Train mae:0.156723 Test loss:0.683592 Test mae:0.370811\n",
            "\n",
            "Epoch:3 Step:150 Train loss:0.123725 Train mae:0.122780 Test loss:0.524164 Test mae:0.292016\n",
            "\n",
            "Epoch:3 Step:160 Train loss:0.146151 Train mae:0.128070 Test loss:0.289553 Test mae:0.286424\n",
            "\n",
            "Epoch:3 Step:170 Train loss:0.167737 Train mae:0.118395 Test loss:0.605168 Test mae:0.360985\n",
            "\n",
            "Epoch:3 Step:180 Train loss:0.124082 Train mae:0.119500 Test loss:0.331381 Test mae:0.255862\n",
            "\n",
            "Epoch:3 Step:190 Train loss:0.160737 Train mae:0.143032 Test loss:0.315855 Test mae:0.273055\n",
            "\n",
            "Epoch:3 Step:200 Train loss:0.244098 Train mae:0.170005 Test loss:0.607870 Test mae:0.344795\n",
            "\n",
            "Epoch:3 Step:210 Train loss:0.127225 Train mae:0.136786 Test loss:0.548287 Test mae:0.360144\n",
            "\n",
            "Epoch:3 Step:220 Train loss:0.104840 Train mae:0.114731 Test loss:0.722466 Test mae:0.470846\n",
            "\n",
            "Epoch:3 Step:230 Train loss:0.174836 Train mae:0.137815 Test loss:0.363020 Test mae:0.313445\n",
            "\n",
            "Epoch:3 Step:240 Train loss:0.114270 Train mae:0.118573 Test loss:0.311158 Test mae:0.309703\n",
            "\n",
            "Epoch:3 Step:250 Train loss:0.205733 Train mae:0.156122 Test loss:0.576527 Test mae:0.328076\n",
            "\n",
            "Epoch:3 Step:260 Train loss:0.172448 Train mae:0.131145 Test loss:0.251190 Test mae:0.205627\n",
            "\n",
            "Epoch:3 Step:270 Train loss:0.146988 Train mae:0.142846 Test loss:0.222897 Test mae:0.203083\n",
            "\n",
            "Epoch:3 Step:280 Train loss:0.419102 Train mae:0.175755 Test loss:0.285335 Test mae:0.249619\n",
            "\n",
            "Epoch:4 Step:0 Train loss:0.182617 Train mae:0.221330 Test loss:0.333400 Test mae:0.360700\n",
            "\n",
            "Epoch:4 Step:10 Train loss:0.286373 Train mae:0.235945 Test loss:0.224512 Test mae:0.277136\n",
            "\n",
            "Epoch:4 Step:20 Train loss:0.355504 Train mae:0.319419 Test loss:0.665209 Test mae:0.677740\n",
            "\n",
            "Epoch:4 Step:30 Train loss:0.224019 Train mae:0.184997 Test loss:0.313443 Test mae:0.290751\n",
            "\n",
            "Epoch:4 Step:40 Train loss:0.149438 Train mae:0.134322 Test loss:0.185266 Test mae:0.196256\n",
            "\n",
            "Epoch:4 Step:50 Train loss:0.140903 Train mae:0.136819 Test loss:0.373431 Test mae:0.249109\n",
            "\n",
            "Epoch:4 Step:60 Train loss:0.229789 Train mae:0.178421 Test loss:0.350166 Test mae:0.276592\n",
            "\n",
            "Epoch:4 Step:70 Train loss:0.183676 Train mae:0.115246 Test loss:0.268168 Test mae:0.211723\n",
            "\n",
            "Epoch:4 Step:80 Train loss:0.134432 Train mae:0.142767 Test loss:0.202640 Test mae:0.219931\n",
            "\n",
            "Epoch:4 Step:90 Train loss:0.137924 Train mae:0.131072 Test loss:0.347020 Test mae:0.249373\n",
            "\n",
            "Epoch:4 Step:100 Train loss:0.303321 Train mae:0.204492 Test loss:0.423763 Test mae:0.339917\n",
            "\n",
            "Epoch:4 Step:110 Train loss:0.501182 Train mae:0.431780 Test loss:0.461688 Test mae:0.405311\n",
            "\n",
            "Epoch:4 Step:120 Train loss:0.397458 Train mae:0.318864 Test loss:0.364143 Test mae:0.323352\n",
            "\n",
            "Epoch:4 Step:130 Train loss:0.516908 Train mae:0.369225 Test loss:0.318694 Test mae:0.334964\n",
            "\n",
            "Epoch:4 Step:140 Train loss:0.495975 Train mae:0.397777 Test loss:0.454150 Test mae:0.469125\n",
            "\n",
            "Epoch:4 Step:150 Train loss:0.181562 Train mae:0.147746 Test loss:0.254029 Test mae:0.194762\n",
            "\n",
            "Epoch:4 Step:160 Train loss:0.175847 Train mae:0.135492 Test loss:0.388588 Test mae:0.304869\n",
            "\n",
            "Epoch:4 Step:170 Train loss:0.258664 Train mae:0.208114 Test loss:0.285075 Test mae:0.257637\n",
            "\n",
            "Epoch:4 Step:180 Train loss:0.269120 Train mae:0.254846 Test loss:0.516837 Test mae:0.449224\n",
            "\n",
            "Epoch:4 Step:190 Train loss:0.196830 Train mae:0.159999 Test loss:0.300721 Test mae:0.234013\n",
            "\n",
            "Epoch:4 Step:200 Train loss:0.305829 Train mae:0.221635 Test loss:0.377594 Test mae:0.297848\n",
            "\n",
            "Epoch:4 Step:210 Train loss:0.194656 Train mae:0.179600 Test loss:0.167740 Test mae:0.170901\n",
            "\n",
            "Epoch:4 Step:220 Train loss:0.138325 Train mae:0.139509 Test loss:0.440794 Test mae:0.372272\n",
            "\n",
            "Epoch:4 Step:230 Train loss:0.234042 Train mae:0.195905 Test loss:0.513732 Test mae:0.372806\n",
            "\n",
            "Epoch:4 Step:240 Train loss:0.119574 Train mae:0.118811 Test loss:0.337732 Test mae:0.248613\n",
            "\n",
            "Epoch:4 Step:250 Train loss:0.222971 Train mae:0.180801 Test loss:0.328959 Test mae:0.236824\n",
            "\n",
            "Epoch:4 Step:260 Train loss:0.221659 Train mae:0.179832 Test loss:0.368407 Test mae:0.356990\n",
            "\n",
            "Epoch:4 Step:270 Train loss:0.181376 Train mae:0.169583 Test loss:0.324239 Test mae:0.290398\n",
            "\n",
            "Epoch:4 Step:280 Train loss:0.694411 Train mae:0.294599 Test loss:0.341782 Test mae:0.298191\n",
            "\n",
            "Epoch:5 Step:0 Train loss:0.164507 Train mae:0.171070 Test loss:0.283414 Test mae:0.232214\n",
            "\n",
            "Epoch:5 Step:10 Train loss:0.334936 Train mae:0.290614 Test loss:0.372088 Test mae:0.301221\n",
            "\n",
            "Epoch:5 Step:20 Train loss:0.221858 Train mae:0.165870 Test loss:0.154318 Test mae:0.193712\n",
            "\n",
            "Epoch:5 Step:30 Train loss:0.194317 Train mae:0.168878 Test loss:0.447176 Test mae:0.324915\n",
            "\n",
            "Epoch:5 Step:40 Train loss:0.205805 Train mae:0.221779 Test loss:0.512684 Test mae:0.386178\n",
            "\n",
            "Epoch:5 Step:50 Train loss:0.127163 Train mae:0.124466 Test loss:0.365230 Test mae:0.248521\n",
            "\n",
            "Epoch:5 Step:60 Train loss:0.213119 Train mae:0.153859 Test loss:0.443273 Test mae:0.352144\n",
            "\n",
            "Epoch:5 Step:70 Train loss:0.182847 Train mae:0.117922 Test loss:0.296571 Test mae:0.187633\n",
            "\n",
            "Epoch:5 Step:80 Train loss:0.179282 Train mae:0.138851 Test loss:0.226590 Test mae:0.195945\n",
            "\n",
            "Epoch:5 Step:90 Train loss:0.166092 Train mae:0.177108 Test loss:0.264263 Test mae:0.243255\n",
            "\n",
            "Epoch:5 Step:100 Train loss:0.396414 Train mae:0.248744 Test loss:0.357595 Test mae:0.351231\n",
            "\n",
            "Epoch:5 Step:110 Train loss:0.106719 Train mae:0.114980 Test loss:0.412663 Test mae:0.311590\n",
            "\n",
            "Epoch:5 Step:120 Train loss:0.115179 Train mae:0.117793 Test loss:0.146880 Test mae:0.161554\n",
            "\n",
            "Epoch:5 Step:130 Train loss:0.179157 Train mae:0.148162 Test loss:0.328929 Test mae:0.237849\n",
            "\n",
            "Epoch:5 Step:140 Train loss:0.151088 Train mae:0.125261 Test loss:0.219152 Test mae:0.201318\n",
            "\n",
            "Epoch:5 Step:150 Train loss:0.074580 Train mae:0.091042 Test loss:0.303607 Test mae:0.206906\n",
            "\n",
            "Epoch:5 Step:160 Train loss:0.106559 Train mae:0.113409 Test loss:0.169747 Test mae:0.197175\n",
            "\n",
            "Epoch:5 Step:170 Train loss:0.256366 Train mae:0.239796 Test loss:0.510369 Test mae:0.383178\n",
            "\n",
            "Epoch:5 Step:180 Train loss:0.449052 Train mae:0.392072 Test loss:0.781393 Test mae:0.641640\n",
            "\n",
            "Epoch:5 Step:190 Train loss:0.311981 Train mae:0.234902 Test loss:0.357424 Test mae:0.319716\n",
            "\n",
            "Epoch:5 Step:200 Train loss:0.244043 Train mae:0.178366 Test loss:0.148542 Test mae:0.200152\n",
            "\n",
            "Epoch:5 Step:210 Train loss:0.116536 Train mae:0.130434 Test loss:0.179010 Test mae:0.210677\n",
            "\n",
            "Epoch:5 Step:220 Train loss:0.141589 Train mae:0.163238 Test loss:0.447487 Test mae:0.397670\n",
            "\n",
            "Epoch:5 Step:230 Train loss:0.241714 Train mae:0.182494 Test loss:0.227088 Test mae:0.233577\n",
            "\n",
            "Epoch:5 Step:240 Train loss:0.137657 Train mae:0.142258 Test loss:0.424635 Test mae:0.339645\n",
            "\n",
            "Epoch:5 Step:250 Train loss:0.240154 Train mae:0.180622 Test loss:0.158775 Test mae:0.196143\n",
            "\n",
            "Epoch:5 Step:260 Train loss:0.208637 Train mae:0.159805 Test loss:0.205753 Test mae:0.223083\n",
            "\n",
            "Epoch:5 Step:270 Train loss:0.186298 Train mae:0.176951 Test loss:0.409435 Test mae:0.273102\n",
            "\n",
            "Epoch:5 Step:280 Train loss:0.444384 Train mae:0.185038 Test loss:0.613183 Test mae:0.393142\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k0WSr4sXVnUi"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}